**Цель курсача** - одно и то же устройство разработать разными средствами - ПЛИС и МК (план обучения пересмотрели, поэтому остался только ПЛИС).

У сигналов есть **спектр**. Суть спектра - разложить сигнал на синусоиды. Спектром простой синусоиды является - просто **палка**: 
![Амплитудный спектр синусоиды](m64f76e36.gif)

График спектра не дает представления о **фазе**, поэтому спектр бывает **амплитудный** и **фазовый**.

Любой непрерывный во времени сигнал фиксируется разными способами (например, сигнал пропускается через АЦП, и его эквивалент можно увидеть на экране). Но существует способ представить сигнал не во временной области, а в *частотной*.

## Ряд Фурье
У инженеров нет бесконечной памяти, поэтому они вынуждены любой бесконечный сигнал "обрезать". Взяв только один член ряда Фурье, сигнал (например, меандр) можно описать синусоидой, которая прошла через каждый "бугор" фигуры. Если члена два, то меандр можно описать суммой двух синусоид. Можно взять 5, 7 и больше членов ряда, и график меандра будет описываться все лучше и лучше, приближаясь к идеальной форме.

По большому счету, **ряды Фурье -- это спектр**. Каждая синусоида, участвующая в сумме этих сигналов, есть спектральная составляющая или то, что выше называлось "палкой" спектра. Сам факт, с какой частотой необходимо брать эти синусоиды, определяет *теорема Котельникова* (на западе ее знают как теорему Найквиста-Шеннона).

## Теорема Котельникова в двух словах
Кривая сложной формы (например, кардиограмма) раскладывается на сумму каких-то синусоид (т. е. электрокардиограмму можно разложить в бесконечный ряд Фурье, где этих самых синусоид будет *бесконечность*).

В бесконечность палок становится больше. Когда сокращается расстояние между палками -- все сливается, **спектр становится непрерывной кривой**. Синусоиды, которые входят в состав электрокардиограммы и имеют гигантскую частоту ГГц, вносят ничтожный вклад. Их амплитуда равна нВ.

Хранить сумму бесконечности синусоид слишком затратно. Поэтому инженеры поступают следующим образом:
1) аппроксимируют кривую спектра (заменяют его прямоугольником)
2) отрезают целых хвост спектра, который будет **правее** границы прямоугольника.
Построив площадь под кривой, инженеры устанавливают режущую прямую в той точке, где слева от нее останется 90% от площади, а справа -- 10%.

Наблюдается процесс *сжатия информации*. Из сигнала вывалилось куча синусоид, уходящих в бесконечность. *Их не стало*. По сути дела, сигнал при этом стал более гладким и покатым, потому что ушли высокочастотные составляющие. 

При соотношении уже 70% на 30% может произойти ухудшение сигнала. Такой "водораздел" называется *верхней частотой спектра сигнала*. Именно эта частота фигурирует в теореме Котельникова. При этом верхняя частота спектра сигнала берется самим инженером.

### Так о чем же говорит теорема Котельникова?
На АЦП приходит кардиосигнал (или сигнал с любого датчика). На выходе будет цифровой формат -- каждая точка сигнала через определенный интервал времени переводится в цифровой формат. Перевод производится с темпом *частоты дискретизации* $fd$. Это значит, что, например, при частоте 1 кГц на выходе коды, соответствующие значением сигнала, будут выдаваться с интервалом 1 мс.

При этом можно купить мегагерцовый АЦП, который будет выдавать точки чаще. **Чем больше частота преобразования АЦП, тем больше его цена**.

==*Теорема Котельникова утверждает следующее: если есть отсчеты с сигнала, то чтобы восстановить его без потерь, частота дискретизации должна быть в 2 раза больше, чем верхняя частота спектра.*== "Восстановить сигнал" -- означает "по отсчетам вернуться обратно к аналоговой форме, которая восстановит сигнал до приемлемой формы".

## Основные термины
1. Исходный физический сигнал является **непрерывной функцией времени**. Такие сигналы, определенные во все моменты времени, называют **аналоговыми (analog)**. 
2. Последовательность чисел, представляющая сигнал при цифровой обработке, является **дискретным рядом (discrete series)** и не может полностью соответствовать аналоговому сигналу. 
3. Числа, составляющие последовательность, являются значениями сигнала в отдельные (дискретные) моменты времени и называются **отсчетами сигнала (samples)**. Как правило, отсчеты берутся через равные промежутки времени T, называемые **периодом дискретизации (или интервалом, шагом дискретизации — sample time)**. 
4. Величина, обратная периоду дискретизации, называется **частотой дискретизации (sampling frequency): fд = 1/T** . Соответствующая ей круговая частота определяется следующим образом: **ωд=2π/T**.
5. Процесс преобразования аналогового сигнала в последовательность отсчетов называется **дискретизацией (sampling)**, а результат такого преобразования — **дискретным сигналом**.
6. При обработке сигнала в вычислительных устройствах его отсчеты представляются в виде **двоичных чисел**, имеющих **ограниченное число разрядов**. Вследствие этого отсчеты могут принимать лишь конечное множество значений и, следовательно, при представлении сигнала неизбежно происходит его **округление**. Процесс преобразования отсчетов сигнала в числа называется **квантованием по уровню (quantization)**, а возникающие при этом ошибки округления — **ошибками (или шумами) квантования (quantization error, quantization noise)**.
7. Сигнал, дискретный во времени, но не квантованный по уровню, называется **дискретным (discrete-time) сигналом**. Сигнал, дискретный во времени и квантованный по уровню, называют цифровым (digital) сигналом. 
![[Pasted image 20250523133038.png]]

## Нерекурсивный и рекурсивный фильтры
В общем случае дискретный фильтр **суммирует (с весовыми коэффициентами) некоторое количество входных отсчетов (включая последний) и некоторое количество предыдущих выходных отсчетов** (стр. 209, Сергиенко, уравнение 4.31):
![[Pasted image 20250521113447.png|500]]

1. **НЕРЕКУРСИВНЫЙ ФИЛЬТР**. Такие фильтры суммируют некоторое число входных отсчетов, умножая их при этом на постоянные весовые коэффициенты.
В общем случае при вычислении очередного выходного отсчета y(k) используется **некоторое количество отсчетов входного сигнала и некоторое количество предыдущих отсчетов выходного сигнала**. Ясно, что хотя бы *один* отсчет входного сигнала должен участвовать в вычислениях, иначе **выходной сигнал не будет зависеть от входного**. В противоположность этому, предыдущие отсчеты выходного сигнала могут и не использоваться. Уравнение фильтрации (см. уравнение выше) в этом случае приобретает следующий вид: 
![[Pasted image 20250521125937.png|200]]
Количество используемых предыдущих отсчетов m называется порядком фильтра (**filter order**).

Некоторое количество предыдущих отсчетов входного сигнала хранится в ячейках памяти, которые образуют дискретную линию задержки. Элементы памяти, осуществляющие такую задержку, обозначены на структурной схеме как " z–1", где -1 -- количество тактов задержки. Эти отсчеты умножаются на коэффициенты bi и суммируются, формируя выходной отсчет y(k) (рисунок 4.10):
![[Pasted image 20250521130429.png|400]]
Так как при вычислениях не используются предыдущие отсчеты выходного сигнала, **в схеме отсутствуют обратные связи**. Поэтому такие фильтры называются **нерекурсивными (nonrecursive)**.

**Импульсная характеристика** нерекурсивного фильтра определяется очень просто. Подставим в уравнение (4.31) единичный импульс x0(k) в качестве входного сигнала:
![[Pasted image 20250521131243.png|200]]
Но отсчет x0(k-i) − **равен нулю для всех k, кроме k = i, когда этот отсчет равен единице**. Поэтому мы получаем очень простой результат:
![[Pasted image 20250521131341.png|100]]
то есть **коэффициенты bi являются отсчетами импульсной характеристики фильтра**. Это можно наглядно пояснить с помощью рис. 4.10. При подаче на вход единичного импульса он будет перемещаться по линии задержки, умножаться на коэффициенты и проходить на выход устройства (ведь все остальные входные сигналы сумматора при этом равны нулю). Очевидно, что в реальном устройстве линия задержки содержит конечное число элементов, поэтому **импульсная характеристика нерекурсивного фильтра также является конечной по длительности**. Это обусловило еще одно название таких фильтров — **ФИЛЬТРЫ С КОНЕЧНОЙ ИМПУЛЬСНОЙ ХАРАКТЕРИСТИКОЙ (КИХ-фильтры; английский термин — finite impulse response, FIR)**.

1. **Рекурсивный фильтр**. Рекурсивные фильтры суммируют при расчетах не только входные, но и некоторое количество предыдущих выходных отсчетов сигнала, умножая их при этом на постоянные весовые коэффициенты
Главная отличительная черта фильтров, использующих при вычислениях предыдущие отсчеты выходного сигнала -- из-за наличия обратных связей они могут быть *неустойчивыми*.

Если уравнение фильтрации имеет общий вид (4.1), т. е. **содержит как входные, так и выходные отсчеты**, для реализации такого фильтра в схему, приведенную на рис. 4.10, необходимо добавить **вторую линию задержки** — для хранения выходных отсчетов y(k – i). Получающаяся при этом структура показана на рис. 4.11 (см. рисунок *ниже*). Так как при вычислениях используются предыдущие отсчеты выходного сигнала, **в схеме присутствуют обратные связи**. Поэтому такие фильтры называют рекурсивными (recursive).
![[Pasted image 20250521140231.png|400]]
Наличие в схеме обратных связей позволяет получить **бесконечную импульсную характеристику**, поэтому рекурсивные фильтры называют также **фильтрами с бесконечной импульсной характеристикой (БИХ-фильтры; английский термин — infinite impulse response, IIR)**. По этой же причине рекурсивные фильтры могут быть неустойчивыми.

## Формы реализации дискретных фильтров
Структурная схема, показанная ранее на рис. 4.11, называется **прямой формой реализации рекурсивного фильтра (direct form I)** и не является единственно возможной. 

Рассмотрим еще несколько вариантов.
1. **КАНОНИЧЕСКАЯ ФОРМА**
Разделим общий сумматор в схеме рис. 4.11 на два отдельных — для **рекурсивной** и **нерекурсивной** частей фильтра (рис. 4.12, а). В результате получаем два последовательно соединенных фильтра, один из которых является **нерекурсивным**, а другой, напротив, **содержит только рекурсивную часть**. 

Так как результат последовательного прохождения сигнала через ряд линейных стационарных устройств не зависит от последовательности их соединения, мы можем поменять местами две "половинки" нашего фильтра (рис. 4.12, б). 

Теперь остается заметить, что в обе линии задержки подается один и тот же сигнал, поэтому они **будут содержать одинаковые наборы отсчетов**. Это позволяет **ОБЪЕДИНИТЬ** линии задержки. Полученная в результате схема изображена на рис. 4.13, она называется **канонической формой реализации рекурсивного фильтра (canonic form или direct form II).**
![[Pasted image 20250521135428.png]]
![[Pasted image 20250521135503.png]]
С теоретической точки зрения эти варианты эквивалентны. Однако при практической реализации необходимо обратить внимание на **ряд особенностей**, присущих этим схемам. С одной стороны, при канонической реализации используется **общая линия задержки**, что уменьшает число необходимых ячеек памяти. Однако при этом абсолютные величины отсчетов, "бегающих" в линии задержки, могут существенно превосходить амплитуду входного и выходного сигналов. Это приводит к необходимости **увеличивать разрядность представления чисел в линии задержки** по сравнению с разрядностью входного и выходного сигналов, что **усложняет реализацию устройства**. При прямой реализации (рис. 4.11) в линиях задержки хранятся непосредственно отсчеты входного и выходного сигналов, т. е. повышенная разрядность линий задержки не требуется. Единственным элементом, требующим повышенной разрядности, в данном случае является сумматор, и это учтено в архитектуре микропроцессоров, специально предназначенных для обработки сигналов в реальном времени.

2. **ТРАНСПОНИРОВАННАЯ ФОРМА**
Поменяем в схеме рис. 4.10 последовательность выполнения операций умножения и задержки, используя в каждой ветви отдельную линию задержки на нужное количество тактов. Разделим также общий сумматор на несколько двухвходовых сумматоров. Получившаяся структура показана на рис. 4.14. 
![[Pasted image 20250521153847.png]]

Теперь, рассмотрев любую пару соседних сумматоров, можно заметить, что суммируемые ими сигналы претерпевают некоторую **общую задержку**. Это дает возможность поменять местами операции суммирования и задержки. Получившаяся схема, показанная на рис. 4.15, называется **транспонированной реализацией дискретного фильтра (direct transposed form II)**.
![[Pasted image 20250521154046.png]]
Транспонированная схема позволяет эффективно распараллелить вычисления и потому применяется при реализации дискретных фильтров в виде **специализированных интегральных схем**. В транспонированной схеме можно одновременно выполнять и **все операции умножения**, и **все операции сложения**, поскольку они являются **независимыми** (т. е. не используют в качестве суммируемых величин результаты других сложений). Как видно из схемы рис. 4.15, для расчета выходного сигнала необходимо выполнить **одно умножение и одно сложение**; все остальные операции производят **подготовку промежуточных результатов** для вычисления последующих выходных отсчетов.


